{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "index_cols = ['subject', 'original_row', 'vertex_id', 'vertex_region']\n",
    "\n",
    "def load_and_prepare_data(filepath):\n",
    "    df = pd.read_parquet(filepath).set_index(index_cols).sort_index().reset_index()\n",
    "    return df\n",
    "\n",
    "# Load and prepare data\n",
    "plac = load_and_prepare_data(\"aggregate_fixed_placebo_iterparams_final.parquet.gzip\")\n",
    "mem = load_and_prepare_data(\"aggregate_fixed_memantine_iterparams_final.parquet.gzip\")\n",
    "\n",
    "# Add group identifiers\n",
    "plac['group'] = 'placebo'\n",
    "mem['group'] = 'memantine'\n",
    "\n",
    "# Combine and filter data to ensure perfect alignment\n",
    "combined = pd.concat([\n",
    "    plac.assign(source='plac'),\n",
    "    mem.assign(source='mem')\n",
    "])\n",
    "\n",
    "# First filter: remove invalid sigma values\n",
    "valid_mask = (combined['2'] > 0) & (combined['6'] > 0)\n",
    "combined = combined[valid_mask]\n",
    "\n",
    "# Pivot to align placebo and memantine data\n",
    "pivoted = combined.pivot_table(\n",
    "    index=['subject', 'vertex_region', 'original_row'],\n",
    "    columns='source',\n",
    "    values=['0','1','2','3','5','6','9']\n",
    ").dropna()\n",
    "\n",
    "# Define filter function with adjustable eccentricity\n",
    "def calculate_filter_mask(pivoted, min_ecc=0.5, max_ecc=4.5):\n",
    "    x_plac = pivoted[('0','plac')]\n",
    "    y_plac = pivoted[('1','plac')]\n",
    "    ecc_plac = np.sqrt(x_plac**2 + y_plac**2)\n",
    "    r_plac = pivoted[('9','plac')]\n",
    "    b1_plac = pivoted[('3','plac')]\n",
    "    s1_plac = pivoted[('2','plac')]\n",
    "    s2_plac = pivoted[('6','plac')]\n",
    "\n",
    "    x_mem = pivoted[('0','mem')]\n",
    "    y_mem = pivoted[('1','mem')]\n",
    "    ecc_mem = np.sqrt(x_mem**2 + y_mem**2)\n",
    "    r_mem = pivoted[('9','mem')]\n",
    "    b1_mem = pivoted[('3','mem')]\n",
    "    s1_mem = pivoted[('2','mem')]\n",
    "    s2_mem = pivoted[('6','mem')]\n",
    "\n",
    "    filter_mask = (\n",
    "        (r_mem >= 0.3) &\n",
    "        (r_plac >= 0.3) &\n",
    "        (np.abs(r_mem - r_plac) <= 0.3) &\n",
    "        (ecc_mem > min_ecc) & (ecc_mem < max_ecc) &\n",
    "        (ecc_plac > min_ecc) & (ecc_plac < max_ecc) &\n",
    "        (b1_mem > 0) & (b1_plac > 0) &\n",
    "        (s1_mem < s2_mem) & (s1_plac < s2_plac)\n",
    "    )\n",
    "    return filter_mask\n",
    "\n",
    "# Initialize filtered datasets with default eccentricity range\n",
    "initial_filter_mask = calculate_filter_mask(pivoted)\n",
    "valid_indices = pivoted[initial_filter_mask].index\n",
    "plac_filtered = plac.set_index(['subject', 'vertex_region', 'original_row']).loc[valid_indices].reset_index()\n",
    "mem_filtered = mem.set_index(['subject', 'vertex_region', 'original_row']).loc[valid_indices].reset_index()\n",
    "\n",
    "# Define the Mexican Hat function with new normalization option\n",
    "def DoG_profile(x, sigma1, sigma2, A1=1.0, A2=1.0, normalization='mean_percent', group=None, maxs_avg=None):\n",
    "    sigma1 = max(sigma1, 0.000001)\n",
    "    sigma2 = max(sigma2, 0.000001)\n",
    "    \n",
    "    g1 = A1 * np.exp(-x**2 / (2 * sigma1**2)) / (np.sqrt(2 * np.pi) * sigma1)\n",
    "    g2 = A2 * np.exp(-x**2 / (2 * sigma2**2)) / (np.sqrt(2 * np.pi) * sigma2)\n",
    "    ans = g1 - g2\n",
    "    ans = np.nan_to_num(ans)\n",
    "    \n",
    "    if normalization == 'mean_percent':\n",
    "        mean_val = np.mean(np.abs(ans[ans != 0])) if np.any(ans != 0) else 1\n",
    "        return (ans / mean_val) * 100\n",
    "    elif normalization == 'max':\n",
    "        max_val = np.max(ans) if np.any(ans != 0) else 1\n",
    "        if max_val <= 0:\n",
    "            return ans  # Avoid division by zero or negative max\n",
    "        return ans / max_val\n",
    "    elif normalization == 'maxs_avg':\n",
    "        if maxs_avg is None:\n",
    "            raise ValueError(\"For 'maxs_avg' normalization, maxs_avg parameter must be provided\")\n",
    "        return ans / maxs_avg\n",
    "    elif normalization == 'None':\n",
    "        return ans\n",
    "    else:\n",
    "        return ans\n",
    "\n",
    "def calculate_width_metrics(profile, x):\n",
    "    \"\"\"Calculate FWHM and FWMIN metrics for a profile\"\"\"\n",
    "    peak_val = np.max(profile)\n",
    "    half_max = peak_val / 2\n",
    "    min_val = np.min(profile)\n",
    "    \n",
    "    # Find FWHM\n",
    "    above_hm = profile >= half_max\n",
    "    if np.any(above_hm):\n",
    "        left_idx = np.argmax(above_hm)\n",
    "        right_idx = len(profile) - left_idx - 1\n",
    "        fwhm = np.abs(x[right_idx] - x[left_idx])\n",
    "    else:\n",
    "        fwhm = np.nan\n",
    "    \n",
    "    # Find FWMIN (full width at minimum)\n",
    "    above_min = profile <= min_val\n",
    "    if np.any(above_min):\n",
    "        left_min_idx = np.argmax(above_min)\n",
    "        right_min_idx = len(profile) - left_min_idx - 1\n",
    "        fwmin = np.abs(x[right_min_idx] - x[left_min_idx])\n",
    "    else:\n",
    "        fwmin = np.nan\n",
    "    \n",
    "    return fwhm, fwmin\n",
    "\n",
    "def calculate_profiles_voxel_first(group_data, x_range=(-10, 10, 100), \n",
    "                                 normalization='mean_percent', ci_method='se', maxs_avg=None):\n",
    "    x = np.linspace(*x_range)\n",
    "    profiles = []\n",
    "    \n",
    "    # Filter by selected subjects and regions first\n",
    "    for (subject, region), sub_df in group_data.groupby(['subject', 'vertex_region']):\n",
    "        voxel_profiles = []\n",
    "        for _, row in sub_df.iterrows():\n",
    "            try:\n",
    "                # Normalize individual profiles to peak 1 if normalization is max\n",
    "                norm = 'max' if normalization == 'max' else normalization\n",
    "                profile = DoG_profile(\n",
    "                    x, \n",
    "                    row['2'],  # sigma1\n",
    "                    row['6'],  # sigma2\n",
    "                    row['3'],  # A1\n",
    "                    row['5'],  # A2\n",
    "                    normalization=norm,\n",
    "                    maxs_avg=maxs_avg\n",
    "                )\n",
    "                voxel_profiles.append(profile)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if voxel_profiles:\n",
    "            avg_profile = np.nanmean(voxel_profiles, axis=0)\n",
    "            \n",
    "            # Re-normalize averaged profile to peak 1 if normalization is max\n",
    "            if normalization == 'max':\n",
    "                max_val = np.max(avg_profile) if np.any(avg_profile != 0) else 1\n",
    "                if max_val > 0:\n",
    "                    avg_profile = avg_profile / max_val\n",
    "            \n",
    "            if ci_method == 'percentile':\n",
    "                ci_low = np.percentile(voxel_profiles, 2.5, axis=0)\n",
    "                ci_high = np.percentile(voxel_profiles, 97.5, axis=0)\n",
    "            else:  # standard error\n",
    "                stderr = stats.sem(voxel_profiles, axis=0, nan_policy='omit')\n",
    "                ci_low = avg_profile - 1.96 * stderr\n",
    "                ci_high = avg_profile + 1.96 * stderr\n",
    "            \n",
    "            peak_idx = np.argmax(avg_profile)\n",
    "            fwhm, fwmin = calculate_width_metrics(avg_profile, x)\n",
    "            \n",
    "            profiles.append({\n",
    "                'subject': subject,\n",
    "                'region': region,\n",
    "                'profile': avg_profile,\n",
    "                'ci_low': ci_low,\n",
    "                'ci_high': ci_high,\n",
    "                'x': x,\n",
    "                'n_voxels': len(voxel_profiles),\n",
    "                'peak_values': (ci_low[peak_idx], avg_profile[peak_idx], ci_high[peak_idx]),\n",
    "                'fwhm': fwhm,\n",
    "                'fwmin': fwmin\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(profiles)\n",
    "\n",
    "def calculate_profiles_voxel_first_subject_average(group_data, x_range=(-10, 10, 100), \n",
    "                                                 normalization='mean_percent', ci_method='se', maxs_avg=None):\n",
    "    x = np.linspace(*x_range)\n",
    "    subject_profiles = []\n",
    "    \n",
    "    # First calculate per-subject averages\n",
    "    for subject, subject_df in group_data.groupby('subject'):\n",
    "        region_profiles = []\n",
    "        \n",
    "        for region, region_df in subject_df.groupby('vertex_region'):\n",
    "            voxel_profiles = []\n",
    "            for _, row in region_df.iterrows():\n",
    "                try:\n",
    "                    # Normalize individual profiles to peak 1 if normalization is max\n",
    "                    norm = 'max' if normalization == 'max' else normalization\n",
    "                    profile = DoG_profile(\n",
    "                        x, \n",
    "                        row['2'],  # sigma1\n",
    "                        row['6'],  # sigma2\n",
    "                        row['3'],  # A1\n",
    "                        row['5'],  # A2\n",
    "                        normalization=norm,\n",
    "                        maxs_avg=maxs_avg\n",
    "                    )\n",
    "                    voxel_profiles.append(profile)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if voxel_profiles:\n",
    "                avg_profile = np.nanmean(voxel_profiles, axis=0)\n",
    "                region_profiles.append(avg_profile)\n",
    "        \n",
    "        if region_profiles:\n",
    "            # Average across regions for this subject\n",
    "            subject_avg_profile = np.nanmean(region_profiles, axis=0)\n",
    "            subject_profiles.append(subject_avg_profile)\n",
    "    \n",
    "    if not subject_profiles:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Now average across subjects\n",
    "    final_profile = np.nanmean(subject_profiles, axis=0)\n",
    "    \n",
    "    # Re-normalize averaged profile to peak 1 if normalization is max\n",
    "    if normalization == 'max':\n",
    "        max_val = np.max(final_profile) if np.any(final_profile != 0) else 1\n",
    "        if max_val > 0:\n",
    "            final_profile = final_profile / max_val\n",
    "    \n",
    "    # Handle CI calculation differently for single vs multiple subjects\n",
    "    if len(subject_profiles) > 1:  # Multiple subjects\n",
    "        if ci_method == 'percentile':\n",
    "            ci_low = np.percentile(subject_profiles, 2.5, axis=0)\n",
    "            ci_high = np.percentile(subject_profiles, 97.5, axis=0)\n",
    "        else:  # standard error\n",
    "            stderr = stats.sem(subject_profiles, axis=0, nan_policy='omit')\n",
    "            ci_low = final_profile - 1.96 * stderr\n",
    "            ci_high = final_profile + 1.96 * stderr\n",
    "    else:  # Single subject - use voxel-level variability\n",
    "        voxel_profiles = []\n",
    "        for _, row in group_data.iterrows():\n",
    "            try:\n",
    "                profile = DoG_profile(\n",
    "                    x,\n",
    "                    row['2'],  # sigma1\n",
    "                    row['6'],  # sigma2\n",
    "                    row['3'],  # A1\n",
    "                    row['5'],  # A2\n",
    "                    normalization=normalization,\n",
    "                    maxs_avg=maxs_avg\n",
    "                )\n",
    "                voxel_profiles.append(profile)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if ci_method == 'percentile':\n",
    "            ci_low = np.percentile(voxel_profiles, 2.5, axis=0)\n",
    "            ci_high = np.percentile(voxel_profiles, 97.5, axis=0)\n",
    "        else:\n",
    "            stderr = stats.sem(voxel_profiles, axis=0, nan_policy='omit')\n",
    "            ci_low = final_profile - 1.96 * stderr\n",
    "            ci_high = final_profile + 1.96 * stderr\n",
    "    \n",
    "    peak_idx = np.argmax(final_profile)\n",
    "    fwhm, fwmin = calculate_width_metrics(final_profile, x)\n",
    "    \n",
    "    return pd.DataFrame([{\n",
    "        'profile': final_profile,\n",
    "        'ci_low': ci_low,\n",
    "        'ci_high': ci_high,\n",
    "        'x': x,\n",
    "        'n_voxels': len(group_data),\n",
    "        'peak_values': (ci_low[peak_idx], final_profile[peak_idx], ci_high[peak_idx]),\n",
    "        'fwhm': fwhm,\n",
    "        'fwmin': fwmin\n",
    "    }])\n",
    "\n",
    "def calculate_profiles_param_first(group_data, x_range=(-10, 10, 100), normalization='mean_percent', maxs_avg=None):\n",
    "    x = np.linspace(*x_range)\n",
    "    profiles = []\n",
    "    \n",
    "    # Group by subject and region first\n",
    "    for (subject, region), sub_df in group_data.groupby(['subject', 'vertex_region']):\n",
    "        if len(sub_df) == 0:\n",
    "            continue\n",
    "        \n",
    "        mean_params = {\n",
    "            'sigma1': np.mean(sub_df['2']),\n",
    "            'sigma2': np.mean(sub_df['6']),\n",
    "            'A1': np.mean(sub_df['3']),\n",
    "            'A2': np.mean(sub_df['5'])\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Normalize individual profiles to peak 1 if normalization is max\n",
    "            norm = 'max' if normalization == 'max' else normalization\n",
    "            profile = DoG_profile(\n",
    "                x,\n",
    "                mean_params['sigma1'],\n",
    "                mean_params['sigma2'],\n",
    "                mean_params['A1'],\n",
    "                mean_params['A2'],\n",
    "                normalization=norm,\n",
    "                maxs_avg=maxs_avg\n",
    "            )\n",
    "            fwhm, fwmin = calculate_width_metrics(profile, x)\n",
    "            \n",
    "            profiles.append({\n",
    "                'subject': subject,\n",
    "                'region': region,\n",
    "                'profile': profile,\n",
    "                'x': x,\n",
    "                'n_voxels': len(sub_df),\n",
    "                'fwhm': fwhm,\n",
    "                'fwmin': fwmin\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # If multiple subjects/regions selected, average their profiles\n",
    "    if len(profiles) > 1:\n",
    "        all_profiles = [p['profile'] for p in profiles]\n",
    "        avg_profile = np.mean(all_profiles, axis=0)\n",
    "        \n",
    "        # Re-normalize averaged profile to peak 1 if normalization is max\n",
    "        if normalization == 'max':\n",
    "            max_val = np.max(avg_profile) if np.any(avg_profile != 0) else 1\n",
    "            if max_val > 0:\n",
    "                avg_profile = avg_profile / max_val\n",
    "        \n",
    "        fwhm, fwmin = calculate_width_metrics(avg_profile, x)\n",
    "        \n",
    "        return pd.DataFrame([{\n",
    "            'profile': avg_profile,\n",
    "            'x': x,\n",
    "            'n_voxels': sum(p['n_voxels'] for p in profiles),\n",
    "            'fwhm': fwhm,\n",
    "            'fwmin': fwmin\n",
    "        }])\n",
    "    elif len(profiles) == 1:\n",
    "        return pd.DataFrame(profiles)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Create widgets\n",
    "subject_options = sorted(plac['subject'].unique().tolist())\n",
    "region_options = sorted(plac['vertex_region'].unique().tolist())\n",
    "normalization_options = ['mean_percent', 'max', 'maxs_avg', 'none']  # Added 'maxs_avg'\n",
    "average_method_options = [\n",
    "    ('Vertex pRFs, then avg pRFs', 'voxel_first'),\n",
    "    ('Avg parameters, then pRF', 'param_first'),\n",
    "    ('Vertex pRFs, then avg subject, then avg subjects', 'voxel_first_subject_avg')\n",
    "]\n",
    "ci_method_options = [\n",
    "    ('Standard Error', 'se'),\n",
    "    ('Percentile (95% CI)', 'percentile')\n",
    "]\n",
    "\n",
    "# Eccentricity filter widgets\n",
    "min_ecc_widget = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.0,\n",
    "    max=4.5,\n",
    "    step=0.5,\n",
    "    description='Min Eccentricity:',\n",
    "    disabled=False,\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "max_ecc_widget = widgets.FloatSlider(\n",
    "    value=4.5,\n",
    "    min=0.0,\n",
    "    max=4.5,\n",
    "    step=0.5,\n",
    "    description='Max Eccentricity:',\n",
    "    disabled=False,\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Zoom control widgets\n",
    "xmin_widget = widgets.FloatSlider(\n",
    "    value=-7.5,\n",
    "    min=-10,\n",
    "    max=0,\n",
    "    step=0.5,\n",
    "    description='X-min:',\n",
    "    disabled=False,\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "xmax_widget = widgets.FloatSlider(\n",
    "    value=7.5,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=0.5,\n",
    "    description='X-max:',\n",
    "    disabled=False,\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "ymin_widget = widgets.BoundedFloatText(\n",
    "    value=-0.02,\n",
    "    min=-0.3,\n",
    "    max=0,\n",
    "    step=0.01,\n",
    "    description='Y-min:',\n",
    "    disabled=False,\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "ymax_widget = widgets.BoundedFloatText(\n",
    "    value=0.01,\n",
    "    min=0,\n",
    "    max=0.3,\n",
    "    step=0.01,\n",
    "    description='Y-max:',\n",
    "    disabled=False,\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Other widgets\n",
    "subject_widget = widgets.SelectMultiple(\n",
    "    options=subject_options,\n",
    "    value=[subject_options[0]],\n",
    "    description='Subject:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "region_widget = widgets.SelectMultiple(\n",
    "    options=region_options,\n",
    "    value=[region_options[0]],\n",
    "    description='Region:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "normalization_widget = widgets.RadioButtons(\n",
    "    options=normalization_options,\n",
    "    value='maxs_avg',\n",
    "    description='Normalization:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "show_placebo_widget = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Show Placebo',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "show_memantine_widget = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Show Memantine',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "average_method_widget = widgets.RadioButtons(\n",
    "    options=average_method_options,\n",
    "    value='voxel_first_subject_avg',\n",
    "    description='Averaging Method:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "ci_method_widget = widgets.RadioButtons(\n",
    "    options=ci_method_options,\n",
    "    value='se',  # Default to standard error\n",
    "    description='CI Method:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "filter_widget = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Apply Inclusion Filter',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "verbose_widget = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Verbose pRF information',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "show_fwhm_widget = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Show FWHM lines',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "show_fwmin_widget = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Show FWMIN lines',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def update_plot(selected_subject, selected_region, normalization, show_placebo, show_memantine, \n",
    "                average_method, apply_filter, min_ecc, max_ecc,\n",
    "                xmin, xmax, ymin, ymax, verbose, ci_method, show_fwhm, show_fwmin):\n",
    "    global plac_filtered, mem_filtered\n",
    "    \n",
    "    # Recalculate filter if eccentricity range changed or filter toggled\n",
    "    if apply_filter:\n",
    "        current_filter_mask = calculate_filter_mask(pivoted, min_ecc, max_ecc)\n",
    "        valid_indices = pivoted[current_filter_mask].index\n",
    "        plac_filtered = plac.set_index(['subject', 'vertex_region', 'original_row']).loc[valid_indices].reset_index()\n",
    "        mem_filtered = mem.set_index(['subject', 'vertex_region', 'original_row']).loc[valid_indices].reset_index()\n",
    "    \n",
    "    # Use filtered or unfiltered data\n",
    "    if apply_filter:\n",
    "        plac_data = plac_filtered.copy()\n",
    "        mem_data = mem_filtered.copy()\n",
    "    else:\n",
    "        plac_data = plac.copy()\n",
    "        mem_data = mem.copy()\n",
    "    \n",
    "    # Apply subject and region filters BEFORE calculating maxs_avg\n",
    "    if selected_subject:\n",
    "        plac_data = plac_data[plac_data['subject'].isin(selected_subject)]\n",
    "        mem_data = mem_data[mem_data['subject'].isin(selected_subject)]\n",
    "    if selected_region:\n",
    "        plac_data = plac_data[plac_data['vertex_region'].isin(selected_region)]\n",
    "        mem_data = mem_data[mem_data['vertex_region'].isin(selected_region)]\n",
    "    \n",
    "    groups_to_show = []\n",
    "    if show_placebo:\n",
    "        groups_to_show.append(('placebo', 'blue', plac_data))\n",
    "    if show_memantine:\n",
    "        groups_to_show.append(('memantine', 'red', mem_data))\n",
    "    \n",
    "    if not groups_to_show:\n",
    "        print(\"Please select at least one group to show\")\n",
    "        return\n",
    "    \n",
    "    # Calculate maxs_avg if needed for normalization, now using filtered & selected data\n",
    "    maxs_avg = None\n",
    "    if normalization == 'maxs_avg' and len(groups_to_show) == 2:\n",
    "        max_values = []\n",
    "        for group_name, group_color, group_data in groups_to_show:\n",
    "            if average_method == 'voxel_first':\n",
    "                profiles_df = calculate_profiles_voxel_first(\n",
    "                    group_data, \n",
    "                    normalization='None',\n",
    "                    ci_method=ci_method\n",
    "                )\n",
    "            elif average_method == 'voxel_first_subject_avg':\n",
    "                profiles_df = calculate_profiles_voxel_first_subject_average(\n",
    "                    group_data,\n",
    "                    normalization='None',\n",
    "                    ci_method=ci_method\n",
    "                )\n",
    "            else:\n",
    "                profiles_df = calculate_profiles_param_first(group_data, normalization='None')\n",
    "            \n",
    "            if not profiles_df.empty:\n",
    "                max_values.append(np.max(profiles_df['profile'].iloc[0]))\n",
    "        \n",
    "        if len(max_values) == 2:\n",
    "            maxs_avg = np.mean(max_values)\n",
    "\n",
    "    # Prepare verbose output\n",
    "    verbose_output = {\"placebo\": [], \"memantine\": []}\n",
    "    param_values = {\"placebo\": {}, \"memantine\": {}}  # To store parameter values\n",
    "    \n",
    "    # Create figure and axes here\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "    for group_name, group_color, group_data in groups_to_show:\n",
    "        # Apply subject and region filters\n",
    "        if selected_subject:\n",
    "            group_data = group_data[group_data['subject'].isin(selected_subject)]\n",
    "        if selected_region:\n",
    "            group_data = group_data[group_data['vertex_region'].isin(selected_region)]\n",
    "        \n",
    "        if group_data.empty:\n",
    "            print(f\"No data available for {group_name} with current filters\")\n",
    "            continue\n",
    "            \n",
    "        # Fix normalization for max to recalc profiles with normalization='max'\n",
    "        norm_to_use = normalization\n",
    "        if normalization == 'max':\n",
    "            norm_to_use = 'max'\n",
    "        elif normalization == 'maxs_avg':\n",
    "            norm_to_use = normalization\n",
    "        else:\n",
    "            norm_to_use = normalization\n",
    "        \n",
    "        if average_method == 'voxel_first':\n",
    "            profiles_df = calculate_profiles_voxel_first(\n",
    "                group_data, \n",
    "                normalization=norm_to_use,\n",
    "                ci_method=ci_method,\n",
    "                maxs_avg=maxs_avg\n",
    "            )\n",
    "        elif average_method == 'voxel_first_subject_avg':\n",
    "            profiles_df = calculate_profiles_voxel_first_subject_average(\n",
    "                group_data,\n",
    "                normalization=norm_to_use,\n",
    "                ci_method=ci_method,\n",
    "                maxs_avg=maxs_avg\n",
    "            )\n",
    "        else:\n",
    "            profiles_df = calculate_profiles_param_first(group_data, normalization=norm_to_use, maxs_avg=maxs_avg)\n",
    "        \n",
    "        if profiles_df.empty:\n",
    "            print(f\"No valid profiles calculated for {group_name} with current filters\")\n",
    "            continue\n",
    "        \n",
    "        # All plotting must be done here, inside update_plot, after ax1, ax2 defined\n",
    "        label = 'Placebo' if group_name == 'placebo' else 'Memantine'\n",
    "\n",
    "        # Prepare data for plotting\n",
    "        x = profiles_df['x'].iloc[0]\n",
    "        profile = profiles_df['profile'].iloc[0]\n",
    "        fwhm = profiles_df['fwhm'].iloc[0]\n",
    "        fwmin = profiles_df['fwmin'].iloc[0]\n",
    "        \n",
    "        # Calculate additional parameters\n",
    "        profile_max = np.max(profile)\n",
    "        profile_min = np.min(profile)\n",
    "        max_min_ratio = profile_max / abs(profile_min) if profile_min != 0 else float('inf')\n",
    "        \n",
    "        # Get parameter averages from the original data\n",
    "        beta1 = group_data['3'].mean()\n",
    "        beta2 = group_data['5'].mean()\n",
    "        sigma1 = group_data['2'].mean()\n",
    "        sigma2 = group_data['6'].mean()\n",
    "        \n",
    "        # Store parameter values\n",
    "        param_values[group_name] = {\n",
    "            'max': profile_max,\n",
    "            'min': profile_min,\n",
    "            'max_min_ratio': max_min_ratio,\n",
    "            'beta1': beta1,\n",
    "            'beta2': beta2,\n",
    "            'sigma1': sigma1,\n",
    "            'sigma2': sigma2,\n",
    "            'fwhm': fwhm,\n",
    "            'fwmin': fwmin\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            verbose_output[group_name].append(f\"--- {label} Profile Information ---\")\n",
    "            verbose_output[group_name].append(f\"Number of Vertices Plotted: {profiles_df['n_voxels'].sum()}\")\n",
    "            if average_method == 'voxel_first_subject_avg':\n",
    "                verbose_output[group_name].append(f\"Number of Subjects: {len(selected_subject) if selected_subject else 'All'}\")\n",
    "            verbose_output[group_name].append(f\"FWHM: {fwhm:.2f} degrees\")\n",
    "            if not np.isnan(fwmin):\n",
    "                verbose_output[group_name].append(f\"FWMIN: {fwmin:.2f} degrees\")\n",
    "            else:\n",
    "                verbose_output[group_name].append(\"FWMIN: Not applicable (no negative component)\")\n",
    "            \n",
    "            if average_method in ['voxel_first', 'voxel_first_subject_avg']:\n",
    "                peak_idx = np.argmax(profile)\n",
    "                peak_x = x[peak_idx]  # Define peak_x here to fix NameError\n",
    "                verbose_output[group_name].append(f\"At peak response (x={peak_x:.1f}):\")\n",
    "                verbose_output[group_name].append(f\"  Lower CI: {profiles_df['ci_low'].iloc[0][peak_idx]:.4f}\")\n",
    "                verbose_output[group_name].append(f\"  Mean:     {profile[peak_idx]:.4f}\")\n",
    "                verbose_output[group_name].append(f\"  Upper CI: {profiles_df['ci_high'].iloc[0][peak_idx]:.4f}\")\n",
    "                verbose_output[group_name].append(f\"  CI Range: {profiles_df['ci_high'].iloc[0][peak_idx] - profiles_df['ci_low'].iloc[0][peak_idx]:.4f}\")\n",
    "\n",
    "        # Plotting code using ax1, ax2\n",
    "        ax1.plot(x, profile, color=group_color, label=label)\n",
    "        if average_method in ['voxel_first', 'voxel_first_subject_avg']:\n",
    "            ci_low = profiles_df['ci_low'].iloc[0]\n",
    "            ci_high = profiles_df['ci_high'].iloc[0]\n",
    "            ax1.fill_between(x, ci_low, ci_high, color=group_color, alpha=0.2, label=f'{label} 95% CI')\n",
    "            ax2.plot(x, profile, color=group_color)\n",
    "            ax2.fill_between(x, ci_low, ci_high, color=group_color, alpha=0.2)\n",
    "        else:\n",
    "            ax2.plot(x, profile, color=group_color)\n",
    "\n",
    "        # Add FWHM and FWMIN visualization if requested\n",
    "        if show_fwhm and not np.isnan(fwhm):\n",
    "            # Find the x positions where profile crosses half max\n",
    "            above_hm = profile >= (np.max(profile) / 2)\n",
    "            left_idx = np.argmax(above_hm)\n",
    "            right_idx = len(profile) - left_idx - 1\n",
    "            left_x = x[left_idx]\n",
    "            right_x = x[right_idx]\n",
    "            \n",
    "            # Draw FWHM lines\n",
    "            ax1.plot([left_x, right_x], [(np.max(profile) / 2), (np.max(profile) / 2)], color=group_color, linestyle=':', alpha=0.5)\n",
    "            ax1.text((left_x + right_x)/2, (np.max(profile) / 2), f'FWHM={fwhm:.1f}°', \n",
    "                    ha='center', va='bottom', color=group_color)\n",
    "            \n",
    "            ax2.plot([left_x, right_x], [(np.max(profile) / 2), (np.max(profile) / 2)], color=group_color, linestyle=':', alpha=0.5)\n",
    "            \n",
    "        if not np.isnan(fwmin):\n",
    "            min_val = np.min(profile)\n",
    "            \n",
    "            # Find the x positions where profile equals minimum\n",
    "            above_min = profile <= min_val\n",
    "            left_min_idx = np.argmax(above_min)\n",
    "            right_min_idx = len(profile) - left_min_idx - 1\n",
    "            left_min_x = x[left_min_idx]\n",
    "            right_min_x = x[right_min_idx]\n",
    "            \n",
    "            # Draw FWMIN lines\n",
    "            ax1.plot([left_min_x, right_min_x], [min_val, min_val], color=group_color, linestyle='--', alpha=0.5)\n",
    "            ax1.text((left_min_x + right_min_x)/2, min_val, f'FWMIN={fwmin:.1f}°', \n",
    "                    ha='center', va='top', color=group_color)\n",
    "            \n",
    "            ax2.plot([left_min_x, right_min_x], [min_val, min_val], color=group_color, linestyle='--', alpha=0.5)\n",
    "            ax2.text((left_min_x + right_min_x)/2, min_val, f'FWMIN={fwmin:.1f}°', ha='center', va='top', color=group_color)\n",
    "    \n",
    "    # Print verbose output side by side with additional parameters\n",
    "    if verbose:\n",
    "        placebo_lines = verbose_output.get('placebo', [])\n",
    "        memantine_lines = verbose_output.get('memantine', [])\n",
    "        \n",
    "        # Add parameter information to the output\n",
    "        for group in ['placebo', 'memantine']:\n",
    "            if group in param_values and param_values[group]:\n",
    "                params = param_values[group]\n",
    "                verbose_output[group].append(f\"  Profile Max: {params['max']:.4f}\")\n",
    "                verbose_output[group].append(f\"  Profile Min: {params['min']:.4f}\")\n",
    "                verbose_output[group].append(f\"  Max/Min Ratio: {params['max_min_ratio']:.4f}\")\n",
    "                verbose_output[group].append(f\"  Beta1 (Center): {params['beta1']:.4f}\")\n",
    "                verbose_output[group].append(f\"  Beta2 (Surround): {params['beta2']:.4f}\")\n",
    "                verbose_output[group].append(f\"  Sigma1 (Center): {params['sigma1']:.4f}\")\n",
    "                verbose_output[group].append(f\"  Sigma2 (Surround): {params['sigma2']:.4f}\")\n",
    "        \n",
    "        # Update lines after adding parameters\n",
    "        placebo_lines = verbose_output.get('placebo', [])\n",
    "        memantine_lines = verbose_output.get('memantine', [])\n",
    "        \n",
    "        # Determine maximum number of lines for padding\n",
    "        max_lines = max(len(placebo_lines), len(memantine_lines))\n",
    "        placebo_lines += [''] * (max_lines - len(placebo_lines))\n",
    "        memantine_lines += [''] * (max_lines - len(memantine_lines))\n",
    "        \n",
    "        # Print side by side\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"COMPARISON OF PROFILE INFORMATION\".center(80))\n",
    "        print(\"=\"*80)\n",
    "        print(f\"{'PLACEBO':<40}{'MEMANTINE':<40}\")\n",
    "        print(\"-\"*80)\n",
    "        for p_line, m_line in zip(placebo_lines, memantine_lines):\n",
    "            print(f\"{p_line:<40}{m_line:<40}\")\n",
    "        \n",
    "    \n",
    "    # Configure main plot\n",
    "    ax1.set_xlabel('Distance from pRF Center (Degrees)')\n",
    "    ax1.set_ylabel('BOLD Response (% of mean)' if normalization == 'mean_percent' else \n",
    "                  'BOLD Response (normalized)' if normalization == 'max' else \n",
    "                  'BOLD Response (normalized by avg max)' if normalization == 'maxs_avg' else 'BOLD Response')\n",
    "    title_parts = []\n",
    "    if selected_subject:\n",
    "        title_parts.append(f\"Subjects: {', '.join(map(str, selected_subject))}\")\n",
    "    if selected_region:\n",
    "        title_parts.append(f\"Regions: {', '.join(selected_region)}\")\n",
    "    title_parts.append(f\"Method: {'Vertex-then-average' if average_method == 'voxel_first' else 'Vertex-then-subject-average' if average_method == 'voxel_first_subject_avg' else 'Parameter-average'}\")\n",
    "    if apply_filter:\n",
    "        title_parts.append(f\"Eccentricity: {min_ecc}-{max_ecc} deg\")\n",
    "    fig.suptitle('PRF Profiles: ' + (' vs '.join([g[0] for g in groups_to_show]) + (' (' + ', '.join(title_parts) + ')' if title_parts else '')))\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Configure zoomed plot (negative values)\n",
    "    ax2.set_xlabel('Distance from pRF Center (Degrees)')\n",
    "    ax2.set_ylabel('BOLD Response')\n",
    "    ax2.set_title('Surround Response Detail')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Set zoomed plot limits based on widget values\n",
    "    ax2.set_xlim(xmin, xmax)\n",
    "    ax2.set_ylim(ymin, ymax)  # Ensure this line is present and not overridden later\n",
    "\n",
    "    # Remove or comment out any dynamic y-limit calculations for ax2 below this line\n",
    "    # (e.g., code that recalculates ymin/ymax and calls ax2.set_ylim again)\n",
    "    \n",
    "    # Add zero lines for reference\n",
    "    ax2.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "    ax2.axvline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a VBox to organize the widgets neatly\n",
    "controls = widgets.VBox([\n",
    "    widgets.HBox([subject_widget, region_widget]),\n",
    "    widgets.HBox([min_ecc_widget, max_ecc_widget]),\n",
    "    normalization_widget,\n",
    "    widgets.HBox([show_placebo_widget, show_memantine_widget]),\n",
    "    average_method_widget,\n",
    "    ci_method_widget,\n",
    "    widgets.HBox([filter_widget, verbose_widget]),\n",
    "    widgets.HBox([show_fwhm_widget, show_fwmin_widget]),\n",
    "    widgets.HTML(\"<h3>Surround Zooming Controls</h3>\"),\n",
    "    widgets.HBox([xmin_widget, xmax_widget]),\n",
    "    widgets.HBox([ymin_widget, ymax_widget])\n",
    "])\n",
    "\n",
    "output = widgets.interactive_output(\n",
    "    update_plot,\n",
    "    {\n",
    "        'selected_subject': subject_widget,\n",
    "        'selected_region': region_widget,\n",
    "        'normalization': normalization_widget,\n",
    "        'show_placebo': show_placebo_widget,\n",
    "        'show_memantine': show_memantine_widget,\n",
    "        'average_method': average_method_widget,\n",
    "        'apply_filter': filter_widget,\n",
    "        'min_ecc': min_ecc_widget,\n",
    "        'max_ecc': max_ecc_widget,\n",
    "        'xmin': xmin_widget,\n",
    "        'xmax': xmax_widget,\n",
    "        'ymin': ymin_widget,\n",
    "        'ymax': ymax_widget,\n",
    "        'verbose': verbose_widget,\n",
    "        'ci_method': ci_method_widget,\n",
    "        'show_fwhm': show_fwhm_widget,\n",
    "        'show_fwmin': show_fwmin_widget\n",
    "    }\n",
    ")\n",
    "\n",
    "display(controls, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
